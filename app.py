import streamlit as st
import asyncio
import edge_tts
import os
from groq import Groq
from streamlit_mic_recorder import mic_recorder
import tempfile

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="My AI American Parent", page_icon="ğŸ‡ºğŸ‡¸")
st.title("ğŸ‡ºğŸ‡¸ Immersive English Environment")
st.caption("Speak to me like a child. I will teach you.")

# --- åˆå§‹åŒ– Groq ---
# é€™è£¡æœƒè‡ªå‹•å¾é›²ç«¯ç’°å¢ƒè®€å–å¯†ç¢¼
api_key = st.secrets["GROQ_API_KEY"]
client = Groq(api_key=api_key)

# --- æ ¸å¿ƒå¤§è…¦è¨­å®š (System Prompt) ---
system_prompt = """
You are a patient, warm American parent. I am your 5-year-old child learning to speak English.
Your Goal: Create a 100% English immersion environment.

Rules:
1. NEVER speak Chinese. Even if I speak Chinese, guess what I mean and reply in English.
2. Use simple vocabulary (CEFR A1/A2 level).
3. Speak slowly and clearly.
4. If I make a grammar mistake, gently repeat the correct sentence (Recasting).
5. Keep answers short (1-2 sentences).
6. Always end with a simple question to encourage me to speak more.
"""

# --- åˆå§‹åŒ–å°è©±ç´€éŒ„ ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": system_prompt}]

# --- å‡½æ•¸ï¼šæ–‡å­—è½‰èªéŸ³ (TTS) ---
async def text_to_speech(text):
    communicate = edge_tts.Communicate(text, "en-US-AnaNeural", rate="-10%") # ä½¿ç”¨æº«æŸ”å¥³è²ï¼Œèªé€Ÿæ”¾æ…¢
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        await communicate.save(fp.name)
        return fp.name

# --- ä»‹é¢ä½ˆå±€ ---
# 1. éŒ„éŸ³æŒ‰éˆ•
c1, c2 = st.columns([1, 3])
with c1:
    st.write("### ğŸ—£ï¸ Speak:")
    # éŒ„éŸ³çµ„ä»¶
    audio = mic_recorder(
        start_prompt="ğŸ”´ Record",
        stop_prompt="â¹ï¸ Stop",
        key='recorder'
    )

# 2. è™•ç†é‚è¼¯
if audio:
    # å­˜ä¸‹éŒ„éŸ³æª”
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
        fp.write(audio['bytes'])
        audio_filename = fp.name

    # A. è€³æœµï¼šç”¨ Groq Whisper è½æ‡‚ä½ èªªä»€éº¼
    try:
        with open(audio_filename, "rb") as file:
            transcription = client.audio.transcriptions.create(
                file=(audio_filename, file.read()),
                model="distil-whisper-large-v3-en", # å…è²»ä¸”å¼·å¤§çš„è½åŠ›æ¨¡å‹
                response_format="json"
            )
        user_text = transcription.text
        st.success(f"You said: {user_text}")

        # B. å¤§è…¦ï¼šæ€è€ƒå›æ‡‰
        st.session_state.messages.append({"role": "user", "content": user_text})
        
        completion = client.chat.completions.create(
            model="llama3-8b-8192", # å…è²»ä¸”æ¥µé€Ÿçš„æ¨¡å‹
            messages=st.session_state.messages,
            temperature=0.7,
            max_tokens=1024,
        )
        ai_response = completion.choices[0].message.content
        st.session_state.messages.append({"role": "assistant", "content": ai_response})
        
        st.info(f"Mom says: {ai_response}")

        # C. å˜´å·´ï¼šåˆæˆèªéŸ³
        audio_file = asyncio.run(text_to_speech(ai_response))
        st.audio(audio_file, format="audio/mp3", autoplay=True)

    except Exception as e:
        st.error(f"Error: {str(e)}")

# é¡¯ç¤ºæ­·å²å°è©± (å¯é¸)
with st.expander("Conversation History"):
    for msg in st.session_state.messages:
        if msg["role"] != "system":
            st.write(f"**{msg['role']}**: {msg['content']}")